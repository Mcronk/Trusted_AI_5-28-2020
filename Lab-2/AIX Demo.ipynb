{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Machine Learning Decisions Using AIX360\n",
    "## Using \"Protodash\" Algorithm\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Black box machine learning models that cannot be understood by people, such as deep neural networks and large ensembles, are achieving impressive accuracy on various tasks. However, as machine learning is increasingly used to inform high stakes decisions, explainability and interpretability of the models is becoming essential. There are many ways to explain: data vs. model, directly interpretable vs. post hoc explanation, local vs. global, static vs. interactive; the appropriate choice depends on the persona of the consumer of the explanation.\n",
    "\n",
    "The AI Explainability 360 Python package includes algorithms that span the different dimensions of ways of explaining along with proxy explainability metrics. The AI Explainability 360 interactive demo provides a gentle introduction to the concepts and capabilities by walking through an example use case from the perspective of different consumer personas. The tutorials and other notebooks offer a deeper, data scientist-oriented introduction. The complete API is also available. \n",
    "\n",
    "For reference information see links below:\n",
    "\n",
    "- AIX360 Demo: https://aix360.mybluemix.net\n",
    "- AIX360 GitHub: https://github.com/IBM/AIX360/\n",
    "- AIX360 API Docs: https://aix360.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Objective\n",
    "\n",
    "Different user roles present different requirements for explanations. In this medical scenario, there are 3 types of users: \n",
    "\n",
    "1. Data scientists: who are interested in very technical explainations of why a model behaves the way it does.\n",
    "2. Doctors: who are interested in knowing what characteristics are similar between current patients and the ones diagnosed with heart disease to better understand why a patient is predicted to have heart disease.\n",
    "3. Patients: who are interested to know what did they do to get heart disease and what they could have done to prevent it.\n",
    "\n",
    "For this reason, AI Explainability 360 offers a collection of algorithms that provide diverse ways of explaining decisions generated by machine learning models. \n",
    "\n",
    "In this notebook you will utilize AIX360 to explain the decisions made to the second group, the doctors. You will use the \"Protodash\" algorithm for this purpose.\n",
    "\n",
    "Upon completing this lab you will learn how to:\n",
    "\n",
    "- Load dataset using a download link\n",
    "- Create, train and evaluate a XGBoost model\n",
    "- Use Protodash Algorithm to extract similar examples and compare them with the current patient's case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "This tutorial uses a Jupyter Notebook, an open-source web applicaiton that allows you to create and share documents that contain instructions as well as live code.\n",
    "\n",
    "The Jupyter Notebooks we are using today is based on a Watson Studio environment, a set of open source packages that provide us with a standardized data analysis tools. At multiple points during the demo, we will important additional tools we need for specific steps:\n",
    "\n",
    "E.g. `import pandas as pd` -> to import the \"pandas\" tool for data manipulation.\n",
    "\n",
    "E.g. `!pip install wget` -> to install a tool \"wget\" to download data from external webpages.\n",
    "\n",
    "Watson Studio also contains a set of functionality that allows a user to pre-define a set of environments down to the package version level as well as define the hardware configurations available to certain users, allowing teams to easily standardize toolsets and resources. If needed, we can also connect our notebooks to GPUs, Apache Spark, and external clusters for higher performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "In order to download the data from UCI Machine Learning Repository, use the `wget` library. Use the following command to install the `wget` library: `!pip install wget` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the code in the cell below downloads the data set and saves it in the local filesystem. The name of the downloadeded file containing the data will be displayed in the output of this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClevelandDataSet loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import pandas as pd\n",
    "\n",
    "link_to_data = 'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "\n",
    "# make sure no duplicates\n",
    "!rm processed.cleveland*.data\n",
    "\n",
    "ClevelandDataSet = wget.download(link_to_data)\n",
    "\n",
    "if (ClevelandDataSet is not None):\n",
    "    print(\"ClevelandDataSet loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The heart disease dataset, pulled from the UC Irvine Machine Learning Repository, contains anonymized information on factors contributing to heart disease. The names and social security numbers from the raw data were removed and replaced with dummy values, allowing for unique identifiers without personally identifiable information. While the full database contains data from multiple locations, the lab today will focus on the Cleveland database, concentrating on either the presence or absence of heart disease.\n",
    "\n",
    "It is a freely available data set on the UCI Machine Learning Repository portal. The Heart Disease Data Set is hosted [here](http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data).\n",
    "\n",
    "The overall heart disease databaes including data from other locations is [here](https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/)\n",
    "\n",
    "### Column Details:\n",
    "1. age - age in years\n",
    "2. sex - sex(1 =  male; 0 = female)\n",
    "3. cp - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 4 = asymptomatic)\n",
    "4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. chol - serum cholestoral in mg/dl\n",
    "6. fbs - fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
    "7. restecg - resting electrocardiographic results (0 = normal; 1 = having ST-T; 2 = hypertrophy)\n",
    "8. thalach - maximum heart rate achieved\n",
    "9. exang - exercise induced angina (1 = yes; 0 = no)\n",
    "10. oldpeak - ST depression induced by exercise relative to rest\n",
    "11. slope - the slope of the peak exercise ST segment (1 = upsloping; 2 = flat; 3 = downsloping)\n",
    "12. ca - number of major vessels (0-3) colored by flourosopy\n",
    "13. thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. num - number of major blood vessels > 50% blocked (angiographic disease status)  \n",
    "\n",
    "Where 1,2,3,4 are considered \"presence\" of heart disease and 0 is \"absence.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore data\n",
    "\n",
    "In this section you will load the data as a Pandas data frame and perform a basic exploration.\n",
    "\n",
    "Load the data in the .csv file, **processed.cleveland.data**, into a Pandas data frame by running the code below. Note that the dataset does not contain header information so that is provided in the col_names variable. The first 5 lines will be displayed by using the .head() method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  restbp   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0   145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0   160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0   120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0   130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0   130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  num  \n",
       "0    3.0  0.0   6.0    0  \n",
       "1    2.0  3.0   3.0    2  \n",
       "2    2.0  2.0   7.0    1  \n",
       "3    3.0  0.0   3.0    0  \n",
       "4    1.0  0.0   3.0    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['age','sex','cp','restbp','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num']\n",
    "\n",
    "heart_data_df = pd.read_csv(ClevelandDataSet, sep=',', header=None, names=col_names, na_filter= True, na_values= {'ca': '?', 'thal': '?'})\n",
    "heart_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Sample data = 303\n",
      "No. of Attributes  = 14\n"
     ]
    }
   ],
   "source": [
    "(samples, attributes) = heart_data_df.shape\n",
    "print(\"No. of Sample data =\", samples )\n",
    "print(\"No. of Attributes  =\", attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a derived attribute that will serve as our target. The goal of the model is to predict whether a patient has a heart problem. The data set as currently constructed does not directly have this information. However, this information can be derived from the `num` attribute. The `num` column and its values pertain to the number of major vessels with more than 50% narrowing (values- 0,1,2,3 or 4) for the corresponding sample data. \n",
    "\n",
    "Therefore, the target column `diagnosed` can derived in the following way: \n",
    "- 'diagnosed' is '0' when 'num' = 0 , indicating normal heart functioning \n",
    "- 'diagnosed' is '1' when 'num' > 0 , indicating a heart problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data_df['diagnosed'] = heart_data_df['num'].map(lambda d: 1 if d > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>restbp</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "      <th>diagnosed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.438944</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.672241</td>\n",
       "      <td>4.734219</td>\n",
       "      <td>0.937294</td>\n",
       "      <td>0.458746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.038662</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>0.937438</td>\n",
       "      <td>1.939706</td>\n",
       "      <td>1.228536</td>\n",
       "      <td>0.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp      restbp        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.438944    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std      9.038662    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  299.000000   \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.672241   \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    0.937438   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal         num   diagnosed  \n",
       "count  301.000000  303.000000  303.000000  \n",
       "mean     4.734219    0.937294    0.458746  \n",
       "std      1.939706    1.228536    0.499120  \n",
       "min      3.000000    0.000000    0.000000  \n",
       "25%      3.000000    0.000000    0.000000  \n",
       "50%      3.000000    0.000000    0.000000  \n",
       "75%      7.000000    2.000000    1.000000  \n",
       "max      7.000000    4.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create\"></a>\n",
    "## 3. Create an XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, ensemble learning models took the lead and became popular among machine learning practitioners.\n",
    "\n",
    "Ensemble learning models employs multiple machine learning algorithms to overcome the potential weaknesses of a single model. For example, if you are going to pick a destination for your next vacation, you probably ask your family and friends, read reviews and blog posts. Based on all the information you have gathered, you make your final decision.\n",
    "\n",
    "This phenomenon is referred as the Wisdom of Crowds (WOC) in social sciences and it states that averaging the answers (prediction or probability) of a group will often result better than the answer of one of its members. The idea is that the collective knowledge of diverse and independent individuals will exceed the knowledge of any one of those individuals, helping to eliminate the noise.\n",
    "\n",
    "XGBoost is an open source library for ensemble based algorithms. It can be used for classification, regression and ranking type of problems. XGBoost supports multiple languages, such as C++, Python, R, and Java. \n",
    "\n",
    "The Python library of XGBoost supports the following API interfaces to train and predict a model, also referred to as a `Booster`: \n",
    "- XGBoost's native APIs pertaining to the `xgboost` package, such as `xgboost.train()` or `xgboost.Booster`\n",
    "- Scikit-Learn based Wrapper APIs: `xgboost.sklearn.XGBClassifier` and `xgboost.sklearn.XGBRegressor`\n",
    "\n",
    "In this section you will learn how to train and test an XGBoost model using the scikit-learn based Wrapper APIs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we will add to the default environment by importing additional packages that will provide us with the specific tools we need for building models using XGBoost and displaying results using matplotlib.\n",
    "\n",
    "XGBoost: https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/\n",
    "\n",
    "matplotlib: https://matplotlib.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Prepare Data\n",
    "In order for our machine learning model to yield accurate results, we need to clean our data. Additionally, the data must be structurd in a specific way to be used as an input in building our machine learning models.\n",
    "\n",
    "We will use Pandas, a software library purpose-built for data manipulation and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1: Cleanse the data\n",
    "Null (empty) values would adversely affect the performance and accuracey of our machine learning model.\n",
    "Below, we check if there are any null rows in our dataset and remove each null rows.\n",
    "\n",
    "`heart_data_df.isnull().sum()` - Count the number of null values for each feature (input variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of features with their corresponding count of null values : \n",
      "---------------------------------------------------------------- \n",
      "age          0\n",
      "sex          0\n",
      "cp           0\n",
      "restbp       0\n",
      "chol         0\n",
      "fbs          0\n",
      "restecg      0\n",
      "thalach      0\n",
      "exang        0\n",
      "oldpeak      0\n",
      "slope        0\n",
      "ca           4\n",
      "thal         2\n",
      "num          0\n",
      "diagnosed    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"List of features with their corresponding count of null values : \")\n",
    "print(\"---------------------------------------------------------------- \")\n",
    "print(heart_data_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of the above cell, there are 6 occurrences where there are null values. The rows containing these null values can be removed so that the data set does not have any incomplete data. The cell below contains the command to remove the rows that contain these null values.\n",
    "\n",
    "`heart_data_df = heart_data_df.dropna(how='any',axis=0)` - For our dataset (heart_data_df) drop any 'NA' (null value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data_df = heart_data_df.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2: Prepare the target data and feature columns\n",
    "A large part of the model building process is choosing which features (inputs) we want to use in prediction (e.g. Does high cholesterol cause heart disease? Or would age be a stronger predictor?). Choosing irrelevant features can decrease the accuracy of our models.\n",
    "\n",
    "For brevity, we have already identified the most relevant features in our data: all our attributes other than the `num` attribute should used.\n",
    "\n",
    "In the code below, we create `feature_cols` as a list of the features we will use. Meaning, we will predict on age, sex, cp, etc...in the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['age','sex','cp','restbp','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']\n",
    "features_df = heart_data_df[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3: Split the data set for training and testing\n",
    "As the target and feature columns have been defined, you can now split the data set into two sets that will be used for training the model and for testing the trained model. \n",
    "\n",
    "A training set is used to build our machine learning model. The test data set is used to assess the performance of our model. The statement below used 67% of our data to train ur model and 33% of our data to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_train, heart_test, target_train, target_test = train_test_split(features_df, heart_data_df.loc[:,'diagnosed'], test_size=0.33, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create the XGBoost Model\n",
    "In the cell below, we create our pipeline which contains the XGBoost classifier. We will use this pipeline to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have set up our pipeline with the XGBoost classifier, we can train it by invoking the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(heart_train,target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now evaluate our model using the testing dataset we created earlier. If we find that our model has low accuracy, we can make adjustments to our models form or input parameters and retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.82%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(heart_test.values)\n",
    "accuracy = accuracy_score(target_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using AIX360\n",
    "\n",
    "\n",
    "In this section, you will install the aix360 library into our environment, allowing us to use the prebuilt algorithms to explain how our model makes decisions. \n",
    "\n",
    "### This step may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install aix360 \n",
    "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n",
    "from project_lib import Project\n",
    "project = Project(project_id='bb85b849-190f-40a1-85b7-cc59bef96005', project_access_token='p-b0ce539bc2fb99e43c428c7c2ea1261802f48fdf')\n",
    "pc = project.project_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./aix360-0.2.0.tar.gz\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (0.15.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (0.23.0)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (1.5.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (0.6.0)\n",
      "Requirement already satisfied: cvxpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (1.0.31)\n",
      "Requirement already satisfied: cvxopt in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (1.2.5)\n",
      "Requirement already satisfied: Image in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (1.5.31)\n",
      "Requirement already satisfied: keras in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (2.2.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (3.0.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (1.15.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (1.2.0)\n",
      "Requirement already satisfied: tensorflow==1.14 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (1.14.0)\n",
      "Requirement already satisfied: xport in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (2.0.2)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (0.14.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (2.21.0)\n",
      "Requirement already satisfied: lime in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (0.2.0.0)\n",
      "Requirement already satisfied: shap in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (0.35.0)\n",
      "Requirement already satisfied: xgboost in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (1.1.0)\n",
      "Requirement already satisfied: bleach>=2.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (3.1.0)\n",
      "Requirement already satisfied: docutils>=0.13.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (0.14)\n",
      "Requirement already satisfied: Pygments in /opt/conda/envs/Python36/lib/python3.6/site-packages (from aix360==0.2.0) (2.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn>=0.21.2->aix360==0.2.0) (2.0.0)\n",
      "Requirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch->aix360==0.2.0) (0.17.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision->aix360==0.2.0) (5.4.1)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy->aix360==0.2.0) (0.6.1)\n",
      "Requirement already satisfied: ecos>=2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy->aix360==0.2.0) (2.0.7.post1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy->aix360==0.2.0) (0.70.9)\n",
      "Requirement already satisfied: scs>=1.1.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cvxpy->aix360==0.2.0) (2.1.2)\n",
      "Requirement already satisfied: django in /opt/conda/envs/Python36/lib/python3.6/site-packages (from Image->aix360==0.2.0) (3.0.6)\n",
      "Requirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from Image->aix360==0.2.0) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras->aix360==0.2.0) (3.13)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras->aix360==0.2.0) (2.9.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras->aix360==0.2.0) (1.0.6)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from keras->aix360==0.2.0) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib->aix360==0.2.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib->aix360==0.2.0) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib->aix360==0.2.0) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib->aix360==0.2.0) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->aix360==0.2.0) (2018.9)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (0.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (0.7.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (0.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (1.14.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (1.16.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (1.11.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (0.32.3)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorflow==1.14->aix360==0.2.0) (3.6.1)\n",
      "Requirement already satisfied: networkx>=1.8 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-image->aix360==0.2.0) (2.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-image->aix360==0.2.0) (1.0.1)\n",
      "Requirement already satisfied: dask[array]>=0.9.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-image->aix360==0.2.0) (1.1.1)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-image->aix360==0.2.0) (0.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->aix360==0.2.0) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->aix360==0.2.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->aix360==0.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->aix360==0.2.0) (1.24.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lime->aix360==0.2.0) (4.31.1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/Python36/lib/python3.6/site-packages (from bleach>=2.1.0->aix360==0.2.0) (0.5.1)\n",
      "Requirement already satisfied: dill>=0.3.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from multiprocess->cvxpy->aix360==0.2.0) (0.3.1.1)\n",
      "Requirement already satisfied: sqlparse>=0.2.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from django->Image->aix360==0.2.0) (0.3.1)\n",
      "Requirement already satisfied: asgiref~=3.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from django->Image->aix360==0.2.0) (3.2.7)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->aix360==0.2.0) (40.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360==0.2.0) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360==0.2.0) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from networkx>=1.8->scikit-image->aix360==0.2.0) (4.3.2)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /opt/conda/envs/Python36/lib/python3.6/site-packages (from dask[array]>=0.9.0->scikit-image->aix360==0.2.0) (0.9.0)\n",
      "Building wheels for collected packages: aix360\n",
      "  Building wheel for aix360 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/4e/b4/20/eb4757d58906df66af96c0769f383db4df59ef1c2f3cab491b\n",
      "Successfully built aix360\n",
      "Installing collected packages: aix360\n",
      "  Found existing installation: aix360 0.2.0\n",
      "    Uninstalling aix360-0.2.0:\n",
      "      Successfully uninstalled aix360-0.2.0\n",
      "Successfully installed aix360-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the project variable\n",
    "from project_lib import Project\n",
    "\n",
    "# Fetch the file, for example the tar.gz or whatever installable distribution you created\n",
    "with open(\"aix360-0.2.0.tar.gz\",\"wb\") as f:\n",
    "    f.write(project.get_file(\"aix360-0.2.0.tar.gz\").read())\n",
    "\n",
    "# Install and import the library\n",
    "!pip install \"aix360-0.2.0.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More environment setup. \n",
    "The line `from aix360.algorithms.protodash import ProtodashExplainer` imports ProtoDashExplainer, the algorithm we will use for this lab, from the aix360 library we imported in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from aix360.algorithms.protodash import ProtodashExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Doctor : ProtoDash Explainer - using similar examples\n",
    "\n",
    "We now show how to generate explanations in the form of selecting prototypical or similar user profiles to a patient in question that the doctor may be interested in. This may help the doctor understand the diagnosis our machine learning model in context.\n",
    "\n",
    "In other words, we identify example profiles of patients that our model diagnosed with heart disease and their specific attributes (e.g. age 65, chol 248). We can then understand why another patient was diagnosed by our model with heart disease by comparing his/her attributes (age, chol, etc) with that example 'prototypical' patient and measuring the level of similarity.\n",
    "\n",
    "Note that the selected prototypical patients are profiles that are part of the training set that has been used to train an AI model that predicts whether or not a patient has heart disease. In fact, the method used in this notebook can work even if we are given not just one but a set of patient profiles for which we want to find similar profiles from a training dataset. Additionally, the method computes weights for each prototype showcasing its similarity to the patient(s) in question.\n",
    "\n",
    "The prototypical explanations in AIX360 are obtained using the Protodash algorithm developed in the following work: ProtoDash: [Fast Interpretable Prototype Selection](https://arxiv.org/abs/1707.01212)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Obtain similar samples as explanations for a patient predicted as \"Has Heart Disease\" \n",
    "\n",
    "The following cell will choose a particular patient, whose profile is displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = model.predict(heart_train) # Use trained model to predict train points\n",
    "p_train = p_train.reshape((p_train.shape[0],1))\n",
    "\n",
    "z_train = np.hstack((heart_train, p_train)) \n",
    "z_train_hd = z_train[z_train[:,-1]>=1, :]  # Store instances that were predicted as Has Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Let us now consider patient number 10 who has been diagnosed with heart disease. \n",
    "\n",
    "We select patient number 10 because we know that in the data they are diagnosed with heart disease.\n",
    "\n",
    "We then display:\n",
    "- the patient (sample) we chose.\n",
    "- The prediction made: 'positive' (has heart disease).\n",
    "- Our prediction probabilities (['probability does not have heart disease','probability has heart disease']\n",
    "\n",
    "And the associated patient information (e.g. age=65)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Sample: 10\n",
      "Prediction made by the model: Positive\n",
      "Prediction probabilities: [[0.06186396 0.93813604]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restbp</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosed</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "age              65\n",
       "sex               1\n",
       "cp                4\n",
       "restbp          110\n",
       "chol            248\n",
       "fbs               0\n",
       "restecg           2\n",
       "thalach         158\n",
       "exang             0\n",
       "oldpeak         0.6\n",
       "slope             1\n",
       "ca                2\n",
       "thal              6\n",
       "num               1\n",
       "diagnosed  Positive"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 10\n",
    "class_names = ['Negative', 'Positive']\n",
    "heart_test_np = heart_test.to_numpy()\n",
    "\n",
    "X = heart_test_np[idx].reshape((1,) + heart_test_np[idx].shape)\n",
    "print(\"Chosen Sample:\", idx)\n",
    "print(\"Prediction made by the model:\", class_names[np.argmax(model.predict_proba(X))])\n",
    "print(\"Prediction probabilities:\", model.predict_proba(X))\n",
    "print(\"\")\n",
    "\n",
    "# attach the prediction made by the model to X\n",
    "X = np.hstack((X, model.predict(X).reshape((1,1))))\n",
    "\n",
    "dfx = pd.DataFrame.from_records(X.astype('double')) # Create dataframe with original feature values\n",
    "dfx.head()\n",
    "\n",
    "dfx[15] = class_names[X[0, -1].astype(int)]\n",
    "dfx.columns = heart_data_df.columns\n",
    "dfx.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Find similar patients predicted as \"Has Heart Disease\" using the protodash explainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to how we created our machine learning pipeline, we now create a Protodash explainer and then find similar 'example' patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -2.0000e+04  4e+00  1e+00  1e+00\n",
      " 1:  3.0230e+04 -4.8766e+08  2e+05  1e+00  1e+00\n",
      " 2:  1.3768e+05 -2.0623e+09  8e+05  1e+00  1e+00\n",
      " 3:  1.4801e+05 -2.1778e+09  9e+05  1e+00  1e+00\n",
      " 4:  2.4327e+05 -3.7393e+09  2e+06  1e+00  1e+00\n",
      " 5:  2.0510e+05 -6.2042e+09  3e+06  1e+00  1e+00\n",
      " 6:  4.4445e+05 -2.7879e+10  1e+07  1e+00  1e+00\n",
      " 7:  1.1357e+05 -1.0489e+13  5e+09  1e+00  1e+00\n",
      " 8:  4.2598e+05 -5.5364e+15  4e+12  1e+00  1e+00\n",
      " 9:  4.4519e+12 -1.2608e+22  1e+22  5e-14  7e-04\n",
      "10:  4.4519e+12 -1.2608e+20  1e+20  6e-16  7e-04\n",
      "11:  4.4519e+12 -1.2608e+18  1e+18  2e-16  5e-06\n",
      "12:  4.4519e+12 -1.2626e+16  1e+16  3e-16  7e-08\n",
      "13:  4.4513e+12 -1.4413e+14  1e+14  1e-16  9e-10\n",
      "14:  4.3888e+12 -1.8917e+13  2e+13  1e-16  2e-09\n",
      "15:  1.0990e+10 -3.0034e+13  3e+13  2e-16  2e-09\n",
      "16:  9.4673e+09 -3.2622e+11  3e+11  8e-17  2e-11\n",
      "17:  1.7541e+09 -5.3986e+09  7e+09  2e-16  3e-13\n",
      "18:  2.5503e+08 -2.9906e+08  6e+08  4e-16  3e-14\n",
      "19:  3.5662e+07 -4.2001e+07  8e+07  2e-16  7e-15\n",
      "20:  4.7662e+06 -6.3743e+06  1e+07  2e-16  6e-15\n",
      "21:  5.3592e+05 -1.0520e+06  2e+06  2e-16  8e-16\n",
      "22:  3.3808e+03 -2.1636e+05  2e+05  1e-16  5e-16\n",
      "23: -4.7978e+04 -7.2734e+04  2e+04  1e-16  3e-17\n",
      "24: -5.0230e+04 -5.3240e+04  3e+03  1e-16  1e-16\n",
      "25: -5.1291e+04 -5.2160e+04  9e+02  2e-16  4e-17\n",
      "26: -5.1398e+04 -5.1472e+04  7e+01  1e-16  5e-17\n",
      "27: -5.1411e+04 -5.1417e+04  7e+00  2e-16  4e-17\n",
      "28: -5.1411e+04 -5.1411e+04  1e-01  2e-16  6e-17\n",
      "29: -5.1411e+04 -5.1411e+04  1e-03  2e-16  9e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -3.0000e+04  6e+00  1e+00  1e+00\n",
      " 1:  1.6220e+04 -3.6743e+08  9e+04  1e+00  1e+00\n",
      " 2:  6.0148e+04 -1.4593e+09  4e+05  1e+00  1e+00\n",
      " 3:  6.5935e+05 -8.4496e+09  3e+06  1e+00  1e+00\n",
      " 4:  6.6476e+05 -8.5239e+09  3e+06  1e+00  1e+00\n",
      " 5:  6.3340e+05 -8.5989e+09  3e+06  1e+00  1e+00\n",
      " 6:  1.2970e+05 -3.2736e+10  1e+07  1e+00  1e+00\n",
      " 7: -3.5305e+04 -1.0036e+11  3e+07  1e+00  1e+00\n",
      " 8: -3.6868e+04 -4.1910e+11  1e+08  1e+00  1e+00\n",
      " 9: -3.3900e+04 -5.5492e+12  2e+09  1e+00  1e+00\n",
      "10: -3.3622e+04 -9.7409e+14  3e+11  1e+00  1e+00\n",
      "11:  5.7799e+12 -8.2510e+21  8e+21  4e-13  3e-03\n",
      "12:  5.7799e+12 -8.2510e+19  8e+19  4e-15  2e-04\n",
      "13:  5.7799e+12 -8.2512e+17  8e+17  1e-16  2e-06\n",
      "14:  5.7798e+12 -8.2678e+15  8e+15  2e-16  8e-08\n",
      "15:  5.7694e+12 -9.9243e+13  1e+14  2e-16  4e-09\n",
      "16:  4.9976e+12 -1.5410e+13  2e+13  2e-16  2e-07\n",
      "17:  3.9397e+11 -8.4063e+12  9e+12  2e-16  2e-11\n",
      "18:  1.1513e+11 -2.1381e+11  3e+11  1e-16  9e-13\n",
      "19:  1.7381e+10 -1.9155e+10  4e+10  1e-16  9e-14\n",
      "20:  2.4897e+09 -2.7860e+09  5e+09  2e-16  9e-14\n",
      "21:  3.5439e+08 -3.9933e+08  8e+08  3e-16  2e-14\n",
      "22:  4.9781e+07 -5.8168e+07  1e+08  2e-16  3e-14\n",
      "23:  6.7336e+06 -8.7237e+06  2e+07  2e-16  7e-15\n",
      "24:  7.9703e+05 -1.4098e+06  2e+06  1e-16  2e-15\n",
      "25:  3.3321e+04 -2.7509e+05  3e+05  1e-16  4e-16\n",
      "26: -4.5759e+04 -8.2930e+04  4e+04  1e-16  6e-17\n",
      "27: -4.9856e+04 -5.3809e+04  4e+03  2e-16  1e-16\n",
      "28: -5.1254e+04 -5.2643e+04  1e+03  2e-16  2e-16\n",
      "29: -5.1393e+04 -5.1508e+04  1e+02  9e-17  4e-17\n",
      "30: -5.1414e+04 -5.1424e+04  1e+01  2e-16  8e-17\n",
      "31: -5.1415e+04 -5.1415e+04  7e-01  3e-16  1e-16\n",
      "32: -5.1415e+04 -5.1415e+04  9e-03  1e-16  8e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -4.0000e+04  8e+00  1e+00  1e+00\n",
      " 1:  4.4660e+03 -1.3607e+08  2e+04  1e+00  1e+00\n",
      " 2:  8.6792e+03 -2.0939e+08  4e+04  1e+00  1e+00\n",
      " 3:  1.0006e+04 -3.7229e+08  7e+04  1e+00  1e+00\n",
      " 4:  2.0898e+04 -8.9243e+08  1e+05  1e+00  1e+00\n",
      " 5:  9.5148e+04 -3.3046e+09  6e+05  1e+00  1e+00\n",
      " 6:  9.8633e+04 -3.3952e+09  6e+05  1e+00  1e+00\n",
      " 7:  9.3719e+04 -3.3632e+09  6e+05  1e+00  1e+00\n",
      " 8:  6.2053e+04 -3.2121e+09  6e+05  1e+00  1e+00\n",
      " 9:  1.3809e+05 -5.2169e+09  1e+06  1e+00  1e+00\n",
      "10:  6.7423e+04 -5.8240e+09  1e+06  1e+00  1e+00\n",
      "11:  7.9821e+05 -1.9520e+10  4e+06  1e+00  1e+00\n",
      "12: -2.3741e+04 -2.0704e+11  5e+07  1e+00  1e+00\n",
      "13:  5.7432e+04 -1.8273e+12  4e+08  1e+00  1e+00\n",
      "14:  2.1219e+05 -1.2445e+14  3e+10  1e+00  1e+00\n",
      "15:  4.6311e+12 -2.1780e+21  2e+21  3e-13  2e-04\n",
      "16:  4.6311e+12 -2.1780e+19  2e+19  3e-15  9e-05\n",
      "17:  4.6311e+12 -2.1784e+17  2e+17  1e-16  2e-06\n",
      "18:  4.6304e+12 -2.2138e+15  2e+15  3e-16  2e-08\n",
      "19:  4.5640e+12 -5.7191e+13  6e+13  3e-16  6e-10\n",
      "20:  1.4875e+12 -1.0707e+13  1e+13  2e-16  2e-09\n",
      "21:  3.7210e+11 -7.6901e+11  1e+12  1e-16  1e-10\n",
      "22:  5.4670e+10 -6.0731e+10  1e+11  2e-16  1e-12\n",
      "23:  7.8653e+09 -8.8820e+09  2e+10  2e-16  1e-13\n",
      "24:  1.1242e+09 -1.2587e+09  2e+09  1e-16  7e-14\n",
      "25:  1.5938e+08 -1.8167e+08  3e+08  1e-16  2e-14\n",
      "26:  2.2141e+07 -2.6696e+07  5e+07  3e-16  3e-15\n",
      "27:  2.8905e+06 -4.0983e+06  7e+06  2e-16  6e-15\n",
      "28:  2.9023e+05 -7.0307e+05  1e+06  2e-16  1e-15\n",
      "29: -2.4031e+04 -1.5854e+05  1e+05  3e-16  5e-16\n",
      "30: -5.0445e+04 -6.3549e+04  1e+04  2e-16  1e-16\n",
      "31: -5.1208e+04 -5.1927e+04  7e+02  1e-16  1e-16\n",
      "32: -5.1401e+04 -5.1496e+04  9e+01  1e-16  1e-16\n",
      "33: -5.1419e+04 -5.1428e+04  9e+00  7e-17  1e-16\n",
      "34: -5.1422e+04 -5.1423e+04  1e+00  7e-17  1e-16\n",
      "35: -5.1422e+04 -5.1422e+04  3e-02  9e-17  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -5.0000e+04  1e+01  1e+00  1e+00\n",
      " 1:  1.0375e+03 -4.4879e+07  5e+03  1e+00  1e+00\n",
      " 2:  9.2081e+02 -3.9095e+07  6e+03  1e+00  1e+00\n",
      " 3:  1.5375e+04 -2.9084e+08  4e+04  1e+00  1e+00\n",
      " 4:  1.5426e+04 -3.1446e+08  4e+04  1e+00  1e+00\n",
      " 5:  1.5727e+04 -3.6470e+08  5e+04  1e+00  1e+00\n",
      " 6:  3.1135e+04 -1.2751e+09  1e+05  1e+00  1e+00\n",
      " 7:  2.9415e+05 -7.4231e+09  1e+06  1e+00  1e+00\n",
      " 8:  2.9949e+05 -7.5178e+09  1e+06  1e+00  1e+00\n",
      " 9:  2.8120e+05 -7.6244e+09  1e+06  1e+00  1e+00\n",
      "10:  8.4236e+05 -1.5473e+10  3e+06  1e+00  1e+00\n",
      "11:  8.5144e+05 -1.5611e+10  3e+06  1e+00  1e+00\n",
      "12:  8.2590e+05 -1.5802e+10  3e+06  1e+00  1e+00\n",
      "13:  9.5445e+05 -2.0037e+10  4e+06  1e+00  1e+00\n",
      "14:  4.4993e+05 -2.7349e+10  5e+06  1e+00  1e+00\n",
      "15:  5.9319e+05 -3.9926e+10  8e+06  1e+00  1e+00\n",
      "16:  6.1219e+05 -1.9302e+11  4e+07  1e+00  1e+00\n",
      "17:  8.3048e+05 -2.7259e+12  6e+08  1e+00  1e+00\n",
      "18:  1.2658e+05 -2.2397e+16  1e+13  1e+00  1e+00\n",
      "19:  8.0270e+12 -6.8188e+22  7e+22  3e-13  5e-03\n",
      "20:  8.0270e+12 -6.8188e+20  7e+20  3e-15  3e-03\n",
      "21:  8.0270e+12 -6.8189e+18  7e+18  1e-16  5e-05\n",
      "22:  8.0269e+12 -6.8241e+16  7e+16  3e-16  4e-07\n",
      "23:  8.0260e+12 -7.3496e+14  7e+14  2e-16  4e-09\n",
      "24:  7.9722e+12 -5.9802e+13  7e+13  1e-16  4e-10\n",
      "25:  4.4631e+11 -7.0109e+13  7e+13  2e-16  9e-10\n",
      "26:  2.3185e+11 -2.3776e+12  3e+12  1e-16  3e-11\n",
      "27:  3.9556e+10 -6.7148e+10  1e+11  1e-16  6e-13\n",
      "28:  5.7448e+09 -6.2895e+09  1e+10  2e-16  3e-13\n",
      "29:  8.2020e+08 -9.1965e+08  2e+09  2e-16  6e-14\n",
      "30:  1.1604e+08 -1.3281e+08  2e+08  1e-16  1e-14\n",
      "31:  1.6034e+07 -1.9611e+07  4e+07  2e-16  8e-15\n",
      "32:  2.0560e+06 -3.0433e+06  5e+06  2e-16  3e-15\n",
      "33:  1.8634e+05 -5.3643e+05  7e+05  2e-16  2e-15\n",
      "34: -3.2916e+04 -1.2893e+05  1e+05  2e-16  5e-16\n",
      "35: -4.9654e+04 -5.7863e+04  8e+03  2e-16  2e-16\n",
      "36: -5.0710e+04 -5.2617e+04  2e+03  1e-16  1e-16\n",
      "37: -5.1339e+04 -5.1707e+04  4e+02  2e-16  1e-16\n",
      "38: -5.1414e+04 -5.1451e+04  4e+01  2e-16  1e-16\n",
      "39: -5.1422e+04 -5.1427e+04  5e+00  1e-16  1e-16\n",
      "40: -5.1423e+04 -5.1423e+04  4e-01  2e-16  1e-16\n",
      "41: -5.1423e+04 -5.1423e+04  1e-02  3e-16  2e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/cvxopt/coneprog.py:2111: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'x' in initvals:\n",
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/cvxopt/coneprog.py:2116: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 's' in initvals:\n",
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/cvxopt/coneprog.py:2131: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'y' in initvals:\n",
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/cvxopt/coneprog.py:2136: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'z' in initvals:\n"
     ]
    }
   ],
   "source": [
    "explainer = ProtodashExplainer()\n",
    "(W, S, setValues) = explainer.explain(X, z_train_hd, m=5) # Return weights W, Prototypes S and objective function values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4. Display similar patient user profiles and the extent to which they are similar to the chosen patient.\n",
    "Indicated by the last row in the table below labelled as \"Weight\", weights closer to 1 are more similar to the chosen patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restbp</th>\n",
       "      <td>100</td>\n",
       "      <td>180</td>\n",
       "      <td>164</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>234</td>\n",
       "      <td>327</td>\n",
       "      <td>176</td>\n",
       "      <td>237</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>156</td>\n",
       "      <td>117</td>\n",
       "      <td>90</td>\n",
       "      <td>71</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>0.875186</td>\n",
       "      <td>1.85998e-05</td>\n",
       "      <td>0.000167398</td>\n",
       "      <td>0.0913901</td>\n",
       "      <td>0.0332379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2          3          4\n",
       "age            58           55           59         67         57\n",
       "sex             1            0            1          1          1\n",
       "cp              4            4            4          4          4\n",
       "restbp        100          180          164        120        130\n",
       "chol          234          327          176        237        131\n",
       "fbs             0            0            1          0          0\n",
       "restecg         0            1            2          0          0\n",
       "thalach       156          117           90         71        115\n",
       "exang           0            1            0          0          1\n",
       "oldpeak       0.1          3.4            1          1        1.2\n",
       "slope           1            2            2          2          2\n",
       "ca              1            0            2          0          1\n",
       "thal            7            3            6          3          7\n",
       "num      Positive     Positive     Positive   Positive   Positive\n",
       "Weight   0.875186  1.85998e-05  0.000167398  0.0913901  0.0332379"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.DataFrame.from_records(z_train_hd[S, 0:-1].astype('double'))\n",
    "df = pd.read_csv(ClevelandDataSet, sep=',', header=None, names=col_names, na_filter= True, na_values= {'ca': '?', 'thal': '?'})\n",
    "\n",
    "RP=[]\n",
    "for i in range(S.shape[0]):\n",
    "    RP.append(class_names[z_train_hd[S[i], -1].astype(int)]) # Append class names\n",
    "dfs[13] = RP\n",
    "dfs.columns = df.columns  \n",
    "dfs[\"Weight\"] = np.around(W, 5)/np.sum(np.around(W, 5)) # Calculate normalized importance weights\n",
    "dfs.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5. Compute how similar a feature of a prototypical user is to the chosen patient\n",
    "\n",
    "In the code below we switch the raw values to a measure of similarity (e.g. age for column 0 switched from 58 to 0.18).\n",
    "\n",
    "The more similar the feature of prototypical user is to the patient, the closer its weight is to 1. \n",
    "We can see below that several features for prototypes are quite similar to the chosen applicant. We can use these values to infer why a machine learning model diagnosed an individual patient with heart disease based on the level of similarity in each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restbp</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1     2     3     4\n",
       "age      0.18  0.09  0.23  0.62  0.14\n",
       "sex      1.00  0.08  1.00  1.00  1.00\n",
       "cp       1.00  1.00  1.00  1.00  1.00\n",
       "restbp   0.71  0.09  0.16  0.71  0.50\n",
       "chol     0.81  0.30  0.34  0.85  0.17\n",
       "fbs      1.00  1.00  0.08  1.00  1.00\n",
       "restecg  0.08  0.29  1.00  0.08  0.08\n",
       "thalach  0.93  0.24  0.09  0.05  0.22\n",
       "exang    1.00  0.13  1.00  1.00  0.13\n",
       "oldpeak  0.63  0.08  0.69  0.69  0.58\n",
       "slope    1.00  0.08  0.08  0.08  0.08\n",
       "ca       0.26  0.07  1.00  0.07  0.26\n",
       "thal     0.58  0.19  1.00  0.19  0.58"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z_train_hd[S, 0:-1] # Store chosen prototypes\n",
    "eps = 1e-10 # Small constant defined to eliminate divide-by-zero errors\n",
    "fwt = np.zeros(z.shape)\n",
    "for i in range (z.shape[0]):\n",
    "    for j in range(z.shape[1]):\n",
    "        fwt[i, j] = np.exp(-1 * abs(X[0, j] - z[i,j])/(np.std(z[:, j])+eps)) # Compute feature similarity in [0,1]\n",
    "                \n",
    "# move wts to a dataframe to display\n",
    "dfw = pd.DataFrame.from_records(np.around(fwt.astype('double'), 2))\n",
    "dfw.columns = df.columns[:-1]\n",
    "dfw.transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
